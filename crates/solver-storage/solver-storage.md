# Solver Storage Crate

## Table of Contents
- [Overview](#overview)
- [Architecture](#architecture)
- [Core Components](#core-components)
- [Storage Implementations](#storage-implementations)
- [Design Patterns](#design-patterns)
- [Technical Deep Dive](#technical-deep-dive)
- [Usage Examples](#usage-examples)
- [Testing Strategy](#testing-strategy)
- [Performance Considerations](#performance-considerations)

---

## Overview

The `solver-storage` crate provides a flexible, pluggable storage abstraction layer for the OIF (Order Intent Framework) solver system. It enables persistent and transient data storage with support for indexing, querying, TTL (Time-To-Live), and batch operations.

### Key Features

- üîå **Pluggable Architecture**: Trait-based design allows multiple backend implementations
- üì¶ **Type-Safe Operations**: Generic methods with automatic serialization/deserialization
- üîç **Query Support**: Field-based indexing and filtering capabilities
- ‚è∞ **TTL Management**: Automatic expiration of stored data
- üîí **Concurrency Safe**: Thread-safe operations with proper locking mechanisms
- ‚ö° **Batch Operations**: Optimized bulk read/write operations
- üè≠ **Factory Pattern**: Dynamic backend instantiation from configuration

### Dependencies

```toml
async-trait = "0.1"           # Async trait support
fs2 = "0.4"                   # File locking primitives
serde = "1.0"                 # Serialization framework
serde_json = "1.0"            # JSON serialization
solver-types = { path = ".." } # Common types
thiserror = "2.0"             # Error handling
tokio = "1.0"                 # Async runtime
toml = "..."                  # Configuration format
tracing = "..."               # Logging
```

---

## Architecture

### High-Level Design

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   Application Layer                      ‚îÇ
‚îÇ              (Orders, Intents, Quotes)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  StorageService                          ‚îÇ
‚îÇ        (High-level typed operations)                     ‚îÇ
‚îÇ  ‚Ä¢ store() / retrieve() / update()                       ‚îÇ
‚îÇ  ‚Ä¢ query() / retrieve_all()                              ‚îÇ
‚îÇ  ‚Ä¢ Type-safe with generics                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                       ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               StorageInterface Trait                     ‚îÇ
‚îÇ         (Low-level byte operations)                      ‚îÇ
‚îÇ  ‚Ä¢ get_bytes() / set_bytes() / delete()                  ‚îÇ
‚îÇ  ‚Ä¢ query() / get_batch()                                 ‚îÇ
‚îÇ  ‚Ä¢ exists() / cleanup_expired()                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ                  ‚îÇ
     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îÇ  FileStorage     ‚îÇ  ‚îÇ MemoryStorage   ‚îÇ
     ‚îÇ  - Persistent    ‚îÇ  ‚îÇ - Transient     ‚îÇ
     ‚îÇ  - TTL support   ‚îÇ  ‚îÇ - Testing only  ‚îÇ
     ‚îÇ  - Indexing      ‚îÇ  ‚îÇ - No indexing   ‚îÇ
     ‚îÇ  - File locking  ‚îÇ  ‚îÇ - Simple        ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Layer Responsibilities

1. **Application Layer**: Business logic dealing with domain objects
2. **StorageService**: Type-safe convenience layer with automatic serialization
3. **StorageInterface**: Abstract interface defining storage operations
4. **Implementations**: Concrete storage backends with specific characteristics

---

## Core Components

### 1. StorageInterface Trait

The foundational trait that all storage backends must implement.

```rust
#[async_trait]
pub trait StorageInterface: Send + Sync {
    async fn get_bytes(&self, key: &str) -> Result<Vec<u8>, StorageError>;
    
    async fn set_bytes(
        &self,
        key: &str,
        value: Vec<u8>,
        indexes: Option<StorageIndexes>,
        ttl: Option<Duration>,
    ) -> Result<(), StorageError>;
    
    async fn delete(&self, key: &str) -> Result<(), StorageError>;
    
    async fn exists(&self, key: &str) -> Result<bool, StorageError>;
    
    async fn query(
        &self,
        namespace: &str,
        filter: QueryFilter,
    ) -> Result<Vec<String>, StorageError>;
    
    async fn get_batch(&self, keys: &[String]) 
        -> Result<Vec<(String, Vec<u8>)>, StorageError>;
    
    fn config_schema(&self) -> Box<dyn ConfigSchema>;
    
    async fn cleanup_expired(&self) -> Result<usize, StorageError> {
        Ok(0) // Default: no-op
    }
}
```

**Design Rationale:**
- **Async operations**: All I/O is async for non-blocking concurrency
- **Byte-level interface**: Keeps the trait generic and serialization-agnostic
- **Send + Sync bounds**: Ensures thread-safety for concurrent access
- **Optional features**: TTL and indexing are opt-in for flexibility

### 2. StorageService

High-level wrapper providing typed operations over the raw byte interface.

```rust
pub struct StorageService {
    backend: Box<dyn StorageInterface>,
}
```

**Key Methods:**

#### Store Operations
```rust
// Store with TTL
pub async fn store_with_ttl<T: Serialize>(
    &self,
    namespace: &str,
    id: &str,
    data: &T,
    indexes: Option<StorageIndexes>,
    ttl: Option<Duration>,
) -> Result<(), StorageError>
```

**How it works:**
1. Combines `namespace` and `id` into a composite key: `"namespace:id"`
2. Serializes data to JSON using `serde_json`
3. Delegates to backend's `set_bytes` method
4. Passes through indexes and TTL configuration

**Why this design:**
- **Namespace separation**: Prevents key collisions between different entity types
- **JSON serialization**: Universal format, human-readable for debugging
- **Generic over T**: Type-safe at compile time

#### Retrieve Operations
```rust
pub async fn retrieve<T: DeserializeOwned>(
    &self,
    namespace: &str,
    id: &str,
) -> Result<T, StorageError>
```

**Flow:**
1. Constructs key from namespace and id
2. Calls backend's `get_bytes`
3. Deserializes JSON to type `T`
4. Returns strongly-typed result

#### Update Operations
```rust
pub async fn update<T: Serialize>(
    &self,
    namespace: &str,
    id: &str,
    data: &T,
    indexes: Option<StorageIndexes>,
) -> Result<(), StorageError>
```

**Important distinction from `store()`:**
- **Checks existence first**: Returns `NotFound` error if key doesn't exist
- **Semantic clarity**: Makes update vs create operations explicit
- **Prevents accidental creation**: Useful for ensuring data integrity

#### Query Operations
```rust
pub async fn query<T: DeserializeOwned>(
    &self,
    namespace: &str,
    filter: QueryFilter,
) -> Result<Vec<(String, T)>, StorageError>
```

**Implementation strategy:**
1. Gets matching keys from backend query
2. Uses `get_batch` for efficient bulk retrieval
3. Deserializes each item individually
4. **Graceful degradation**: Logs errors but continues with other items
5. Returns vector of (id, item) tuples

**Why graceful degradation:**
- Corrupted single items don't break entire queries
- Allows partial recovery in production scenarios
- Logs issues for investigation

### 3. StorageIndexes

Builder pattern for specifying queryable fields.

```rust
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct StorageIndexes {
    pub fields: HashMap<String, serde_json::Value>,
}

impl StorageIndexes {
    pub fn new() -> Self { ... }
    
    pub fn with_field(
        mut self, 
        name: impl Into<String>, 
        value: impl Serialize
    ) -> Self { ... }
}
```

**Usage pattern:**
```rust
let indexes = StorageIndexes::new()
    .with_field("status", "pending")
    .with_field("user_id", user_id)
    .with_field("amount", 1000);

service.store("orders", order_id, &order, Some(indexes)).await?;
```

**Design decisions:**
- **Builder pattern**: Fluent, chainable API
- **Type-agnostic values**: Uses `serde_json::Value` for flexibility
- **Optional field**: Not all data needs indexing

### 4. QueryFilter

Enumeration of supported query operations.

```rust
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum QueryFilter {
    Equals(String, serde_json::Value),      // field == value
    NotEquals(String, serde_json::Value),   // field != value
    In(String, Vec<serde_json::Value>),     // field IN values
    NotIn(String, Vec<serde_json::Value>),  // field NOT IN values
    All,                                     // Match everything
}
```

**Query semantics:**
- **Equals**: Direct field match (most efficient)
- **NotEquals**: Inverted match (scans all indexed values)
- **In**: Multiple value match (OR logic)
- **NotIn**: Exclusion filter
- **All**: Retrieves all indexed items in namespace

**Backend responsibility:**
Each backend implements filtering logic differently:
- **FileStorage**: Uses index files with HashMaps
- **MemoryStorage**: Returns empty (no indexing support)
- **Future DB backends**: Would use native SQL/NoSQL queries

### 5. StorageError

Comprehensive error type using `thiserror`.

```rust
#[derive(Debug, Error)]
pub enum StorageError {
    #[error("Not found: {0}")]
    NotFound(String),
    
    #[error("Serialization error: {0}")]
    Serialization(String),
    
    #[error("Backend error: {0}")]
    Backend(String),
    
    #[error("Configuration error: {0}")]
    Configuration(String),
    
    #[error("Expired error: {0}")]
    Expired(String),
}
```

**Error categories:**
- **NotFound**: Key doesn't exist (expected in normal flow)
- **Serialization**: JSON encoding/decoding failures
- **Backend**: I/O errors, permission issues, etc.
- **Configuration**: Invalid config parameters
- **Expired**: Data past TTL (distinct from NotFound)

---

## Storage Implementations

### FileStorage Implementation

The production-ready persistent storage backend.

#### File Format Specification

**Binary Layout:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    File Header                        ‚îÇ
‚îÇ                    (64 bytes)                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Offset  ‚îÇ Size    ‚îÇ Field                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 0-3     ‚îÇ 4 bytes ‚îÇ Magic: "OIFS" (0x4F 49 46 53)   ‚îÇ
‚îÇ 4-5     ‚îÇ 2 bytes ‚îÇ Version: u16 little-endian       ‚îÇ
‚îÇ 6-13    ‚îÇ 8 bytes ‚îÇ Expires: u64 Unix timestamp      ‚îÇ
‚îÇ 14-63   ‚îÇ 50 bytes‚îÇ Padding (reserved)               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ                    Data Payload                       ‚îÇ
‚îÇ                  (variable length)                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Header structure:**
```rust
struct FileHeader {
    magic: [u8; 4],      // b"OIFS"
    version: u16,        // Currently 1
    expires_at: u64,     // Unix timestamp (0 = never expires)
    padding: [u8; 50],   // Future extensions
}
```

**Why this design:**
- **Fixed header size**: Enables efficient TTL checks without reading entire file
- **Magic bytes**: Validates file format and detects corruption
- **Version field**: Allows format evolution while maintaining compatibility
- **Padding**: Reserved space for future features without breaking changes
- **Little-endian**: Standard for modern systems, explicit choice

#### File Header Implementation

```rust
impl FileHeader {
    const MAGIC: &'static [u8; 4] = b"OIFS";
    const VERSION: u16 = 1;
    const SIZE: usize = 64;
    
    fn new(ttl: Duration) -> Self {
        let expires_at = if ttl.is_zero() {
            0  // Permanent storage
        } else {
            SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_secs()
                .saturating_add(ttl.as_secs())
        };
        
        Self {
            magic: *Self::MAGIC,
            version: Self::VERSION,
            expires_at,
            padding: [0; 50],
        }
    }
}
```

**TTL calculation:**
- Uses Unix timestamp for absolute expiration time
- `saturating_add`: Prevents overflow (capped at u64::MAX)
- Zero value means permanent (no expiration)
- Calculated at write time, not read time

**Legacy file support:**
```rust
match FileHeader::deserialize(&data) {
    Ok(header) => {
        if header.is_expired() {
            return Err(StorageError::Expired(key.to_string()));
        }
        Ok(data[FileHeader::SIZE..].to_vec())
    },
    Err(_) => {
        // Legacy file without header, return as-is
        Ok(data)
    },
}
```

**Backward compatibility strategy:**
- Files without magic bytes treated as legacy format
- Legacy files return full content (no header stripping)
- New writes always include header
- Gradual migration path

#### File Path Management

```rust
fn get_file_path(&self, key: &str) -> PathBuf {
    // Sanitize key to be filesystem-safe
    let safe_key = key.replace(['/', ':'], "_");
    self.base_path.join(format!("{}.bin", safe_key))
}
```

**Key sanitization:**
- Replaces `/` and `:` with `_`
- Example: `"orders:12345"` ‚Üí `"orders_12345.bin"`
- Prevents directory traversal attacks
- Makes keys filesystem-compatible

**Why this approach:**
- Simple and predictable mapping
- Reversible for debugging
- No collision risk (keys preserve uniqueness)

#### TTL Configuration System

```rust
pub struct TtlConfig {
    ttls: HashMap<StorageKey, Duration>,
}

impl TtlConfig {
    fn from_config(config: &toml::Value) -> Self {
        let mut ttls = HashMap::new();
        
        if let Some(table) = config.as_table() {
            for storage_key in StorageKey::all() {
                let config_key = format!("ttl_{}", storage_key.as_str());
                if let Some(ttl_value) = table
                    .get(&config_key)
                    .and_then(|v| v.as_integer())
                    .map(|v| v as u64)
                {
                    ttls.insert(storage_key, Duration::from_secs(ttl_value));
                }
            }
        }
        
        Self { ttls }
    }
}
```

**Configuration example:**
```toml
[storage]
type = "file"
storage_path = "./data/storage"
ttl_orders = 3600        # 1 hour
ttl_intents = 7200       # 2 hours
ttl_quotes = 1800        # 30 minutes
```

**Dynamic TTL lookup:**
```rust
fn get_ttl_for_key(&self, key: &str) -> Duration {
    let namespace = key.split(':').next().unwrap_or("");
    
    namespace
        .parse::<StorageKey>()
        .map(|sk| self.ttl_config.get_ttl(sk))
        .unwrap_or(Duration::ZERO)
}
```

**How it works:**
1. Extracts namespace from key (e.g., `"orders:123"` ‚Üí `"orders"`)
2. Parses namespace as `StorageKey` enum
3. Looks up configured TTL
4. Falls back to `Duration::ZERO` (permanent) if not configured

#### Indexing System

**Index file structure:**
```rust
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct NamespaceIndex {
    // Field -> Value -> Set of keys
    // Example: {"status": {"Pending": ["order1", "order2"], 
    //                      "Executed": ["order3"]}}
    pub indexes: HashMap<String, HashMap<serde_json::Value, HashSet<String>>>,
}
```

**Visual representation:**
```
Namespace: "orders"

Index structure:
{
    "status": {
        "pending": {"orders:1", "orders:2", "orders:5"},
        "completed": {"orders:3", "orders:4"}
    },
    "user_id": {
        "alice": {"orders:1", "orders:3"},
        "bob": {"orders:2", "orders:4", "orders:5"}
    }
}

Stored as: orders.index (JSON file)
```

**Index file naming:**
- Pattern: `{namespace}.index`
- Example: `orders.index`, `intents.index`
- Separate index per namespace
- Allows namespace-scoped queries

#### File Locking Mechanism

**Why locking is needed:**
- Prevent concurrent writes corrupting index files
- Enable safe concurrent reads
- Maintain consistency across operations

**Lock file approach:**
```rust
async fn with_index_lock<F, Fut, R>(
    index_path: &Path, 
    operation: F
) -> Result<R, StorageError>
where
    F: FnOnce() -> Fut + Send + 'static,
    Fut: std::future::Future<Output = Result<R, StorageError>> + Send,
    R: Send + 'static,
{
    let lock_path = index_path.with_extension("lock");
    
    // Move to blocking thread for file operations
    let result = tokio::task::spawn_blocking(move || {
        let lock_file = std::fs::OpenOptions::new()
            .create(true)
            .truncate(true)
            .write(true)
            .open(&lock_path)?;
        
        // Acquire exclusive lock (blocking)
        FileExt::lock_exclusive(&lock_file)?;
        
        Ok((lock_file,))
    }).await?;
    
    let (_lock_file,) = result?;
    
    // Perform operation (async context)
    // Lock released when _lock_file is dropped
    operation().await
}
```

**Lock types:**
1. **Exclusive lock** (`lock_exclusive`): For writes
2. **Shared lock** (`lock_shared`): For reads (multiple readers allowed)

**Critical design decisions:**

1. **Blocking operations in spawn_blocking:**
   - `FileExt::lock_exclusive` is a blocking system call
   - Would block entire async executor if called directly
   - `spawn_blocking` runs on separate thread pool
   
2. **Lock file lifecycle:**
   - Created alongside index file
   - Pattern: `{namespace}.lock`
   - Lock released when file handle drops
   - RAII pattern ensures cleanup
   
3. **Lock scope:**
   - Per-namespace, not global
   - Allows concurrent operations on different namespaces
   - Minimizes contention

#### Index Update Operations

```rust
async fn update_indexes(
    &self,
    namespace: &str,
    key: &str,
    indexes: &StorageIndexes,
) -> Result<(), StorageError> {
    let index_path = self.base_path.join(format!("{}.index", namespace));
    
    Self::with_index_lock(&index_path, move || async move {
        // 1. Load existing index or create new
        let mut namespace_index = if index_path_clone.exists() {
            let data = fs::read(&index_path_clone).await?;
            match serde_json::from_slice(&data) {
                Ok(index) => index,
                Err(e) => {
                    tracing::error!("Corrupted index, rebuilding: {}", e);
                    NamespaceIndex::default()
                },
            }
        } else {
            NamespaceIndex::default()
        };
        
        // 2. Remove old index entries for this key
        for (_, value_map) in namespace_index.indexes.iter_mut() {
            for (_, keys) in value_map.iter_mut() {
                keys.remove(&key_owned);
            }
        }
        
        // 3. Add new index entries
        for (field, value) in &indexes_owned.fields {
            namespace_index
                .indexes
                .entry(field.clone())
                .or_default()
                .entry(value.clone())
                .or_default()
                .insert(key_owned.clone());
        }
        
        // 4. Clean up empty entries
        namespace_index.indexes.retain(|_, value_map| {
            value_map.retain(|_, keys| !keys.is_empty());
            !value_map.is_empty()
        });
        
        // 5. Write index atomically
        let temp_path = index_path_clone.with_extension("tmp");
        fs::write(&temp_path, serde_json::to_vec(&namespace_index)?).await?;
        fs::rename(temp_path, index_path_clone).await?;
        
        Ok(())
    }).await
}
```

**Step-by-step breakdown:**

**Step 1: Load existing index**
- Reads index file if exists
- Handles corrupted indexes gracefully (rebuilds from scratch)
- Creates empty index if first write to namespace

**Step 2: Remove old entries**
- Important when updating existing keys
- Prevents stale index entries if indexed fields changed
- Example: Order changes status from "pending" to "completed"

**Step 3: Add new entries**
- Triple-nested structure:
  - `namespace_index.indexes` (field name)
  - `.entry(field)` (field value)
  - `.insert(key)` (store key)
- Uses `or_default()` for clean initialization

**Step 4: Cleanup empty entries**
- Removes fields with no keys
- Removes values with no keys
- Keeps index file lean

**Step 5: Atomic write**
- Write to temporary file first
- Rename to actual file (atomic operation on POSIX)
- Prevents corruption if process crashes during write

#### Query Implementation

```rust
async fn query(
    &self,
    namespace: &str,
    filter: QueryFilter,
) -> Result<Vec<String>, StorageError> {
    let index_path = self.base_path.join(format!("{}.index", namespace));
    
    if !index_path.exists() {
        return Ok(Vec::new());
    }
    
    // Read index with shared lock (multiple readers allowed)
    let namespace_index = Self::with_index_read_lock(&index_path, || async move {
        let data = fs::read(&index_path_clone).await?;
        let index: NamespaceIndex = serde_json::from_slice(&data)?;
        Ok(index)
    }).await?;
    
    let matching_keys: Vec<String> = match filter {
        QueryFilter::All => {
            let mut all_keys = HashSet::new();
            for value_map in namespace_index.indexes.values() {
                for keys in value_map.values() {
                    all_keys.extend(keys.clone());
                }
            }
            all_keys.into_iter().collect()
        },
        QueryFilter::Equals(field, value) => {
            namespace_index
                .indexes
                .get(&field)
                .and_then(|m| m.get(&value))
                .map(|keys| keys.iter().cloned().collect())
                .unwrap_or_default()
        },
        // ... other filter implementations
    };
    
    // Filter out expired entries
    let mut valid_keys = Vec::new();
    for key in matching_keys {
        let path = self.get_file_path(&key);
        if path.exists() {
            if let Ok(data) = fs::read(&path).await {
                if data.len() >= FileHeader::SIZE {
                    if let Ok(header) = FileHeader::deserialize(&data[..FileHeader::SIZE]) {
                        if !header.is_expired() {
                            valid_keys.push(key);
                        }
                    }
                }
            }
        }
    }
    
    Ok(valid_keys)
}
```

**Query execution phases:**

**Phase 1: Index lookup**
- Opens index file with shared lock (allows concurrent reads)
- Deserializes index structure
- Returns empty if no index exists

**Phase 2: Filter application**
- Applies query filter to index
- Different strategies per filter type:
  - `All`: Collects all keys from all fields
  - `Equals`: Direct HashMap lookup (O(1))
  - `NotEquals`: Scans all values except target
  - `In`: Looks up multiple values and unions results
  - `NotIn`: Inverted In logic

**Phase 3: Expiration filtering**
- Checks each result for expiration
- Reads just the header (64 bytes)
- Removes expired keys from results
- Ensures consistency with TTL system

**Performance characteristics:**
- Index lookup: O(1) for Equals, O(n) for others
- Expiration check: O(m) where m = matching keys
- Total: O(1 + m) for Equals queries

#### Atomic Write Operations

```rust
async fn set_bytes(
    &self,
    key: &str,
    value: Vec<u8>,
    indexes: Option<StorageIndexes>,
    ttl: Option<Duration>,
) -> Result<(), StorageError> {
    let path = self.get_file_path(key);
    
    // Create parent directory
    if let Some(parent) = path.parent() {
        fs::create_dir_all(parent).await?;
    }
    
    // Determine TTL
    let ttl = ttl.unwrap_or_else(|| self.get_ttl_for_key(key));
    
    // Create header
    let header = FileHeader::new(ttl);
    let header_bytes = header.serialize();
    
    // Combine header and data
    let mut file_data = Vec::with_capacity(FileHeader::SIZE + value.len());
    file_data.extend_from_slice(&header_bytes);
    file_data.extend_from_slice(&value);
    
    // Write atomically: temp file + rename
    let temp_path = path.with_extension("tmp");
    fs::write(&temp_path, file_data).await?;
    fs::rename(&temp_path, &path).await?;
    
    // Update indexes if provided
    if let Some(indexes) = indexes {
        let namespace = key.split(':').next().unwrap_or("");
        self.update_indexes(namespace, key, &indexes).await?;
    }
    
    Ok(())
}
```

**Atomicity guarantee:**
1. Write to `.tmp` file
2. `fs::rename()` is atomic on POSIX systems
3. Either old or new version exists, never corrupt half-written state
4. Crash-safe during write operation

**Index update ordering:**
- Data file written first
- Indexes updated after
- Ensures data exists before becoming queryable
- Prevents querying non-existent keys

#### Expiration Cleanup

```rust
async fn cleanup_expired_files(&self) -> Result<usize, StorageError> {
    let mut removed = 0;
    let mut entries = fs::read_dir(&self.base_path).await?;
    
    while let Some(entry) = entries.next_entry().await? {
        let path = entry.path();
        if path.extension() == Some(std::ffi::OsStr::new("bin")) {
            match fs::read(&path).await {
                Ok(data) => {
                    if data.len() >= FileHeader::SIZE {
                        if let Ok(header) = FileHeader::deserialize(&data[..FileHeader::SIZE]) {
                            if header.is_expired() {
                                // Extract key from filename
                                let file_name = entry.file_name();
                                let file_str = file_name.to_string_lossy();
                                if let Some(key_part) = file_str.strip_suffix(".bin") {
                                    let key = key_part.replace('_', ":");
                                    // Use delete method for proper index cleanup
                                    if let Err(e) = self.delete(&key).await {
                                        tracing::warn!("Failed to remove expired file: {}", e);
                                    } else {
                                        removed += 1;
                                    }
                                }
                            }
                        }
                    }
                },
                Err(e) => tracing::debug!("Skipping file: {}", e),
            }
        }
    }
    Ok(removed)
}
```

**Cleanup process:**
1. Scans all `.bin` files in storage directory
2. Reads headers only (efficient)
3. Checks expiration timestamps
4. Calls `delete()` for expired files (ensures index cleanup)
5. Logs failures but continues processing
6. Returns count of removed items

**When to run:**
- Background task at regular intervals
- Before queries (optional optimization)
- During system startup (cleanup after downtime)

---

### MemoryStorage Implementation

Simplified in-memory backend for testing and development.

```rust
pub struct MemoryStorage {
    store: Arc<RwLock<HashMap<String, Vec<u8>>>>,
}
```

**Architecture:**
- **Arc**: Allows cloning for shared ownership
- **RwLock**: Read-write lock for concurrency
  - Multiple readers simultaneously
  - Single writer with exclusive access
- **HashMap**: O(1) key-value lookups

**Implementation:**
```rust
#[async_trait]
impl StorageInterface for MemoryStorage {
    async fn get_bytes(&self, key: &str) -> Result<Vec<u8>, StorageError> {
        let store = self.store.read().await;
        store
            .get(key)
            .cloned()
            .ok_or(StorageError::NotFound(key.to_string()))
    }
    
    async fn set_bytes(
        &self,
        key: &str,
        value: Vec<u8>,
        _indexes: Option<StorageIndexes>,
        _ttl: Option<Duration>,
    ) -> Result<(), StorageError> {
        // TTL and indexes ignored
        let mut store = self.store.write().await;
        store.insert(key.to_string(), value);
        Ok(())
    }
    
    async fn query(
        &self,
        _namespace: &str,
        _filter: QueryFilter,
    ) -> Result<Vec<String>, StorageError> {
        // No indexing support
        Ok(Vec::new())
    }
}
```

**Limitations:**
- ‚ùå No TTL support
- ‚ùå No indexing/querying
- ‚ùå No persistence
- ‚ùå No cleanup operations

**Use cases:**
- Unit tests
- Integration tests
- Local development
- Prototyping

**Why these limitations are acceptable:**
- Testing doesn't need persistence
- Queries can be tested with FileStorage in integration tests
- Simplicity makes tests faster and more reliable
- Clear separation: memory = ephemeral, file = persistent

---

## Design Patterns

### 1. Trait-Based Abstraction

**Pattern:**
```rust
pub trait StorageInterface: Send + Sync {
    // Abstract operations
}

impl StorageInterface for FileStorage { ... }
impl StorageInterface for MemoryStorage { ... }
```

**Benefits:**
- Dependency inversion: High-level code depends on abstraction
- Testability: Easy to mock or substitute implementations
- Extensibility: Add new backends without changing consumers
- Type safety: Compile-time verification of interface

**Example usage:**
```rust
fn create_service(backend: Box<dyn StorageInterface>) -> StorageService {
    StorageService::new(backend)
}

// Can use any implementation
let service = create_service(Box::new(FileStorage::new(...)));
let test_service = create_service(Box::new(MemoryStorage::new()));
```

### 2. Factory Pattern

**Implementation:**
```rust
pub type StorageFactory = fn(&toml::Value) -> Result<Box<dyn StorageInterface>, StorageError>;

pub fn create_storage(config: &toml::Value) -> Result<Box<dyn StorageInterface>, StorageError> {
    FileStorageSchema::validate_config(config)?;
    
    let storage_path = config
        .get("storage_path")
        .and_then(|v| v.as_str())
        .unwrap_or("./data/storage");
    
    let ttl_config = TtlConfig::from_config(config);
    
    Ok(Box::new(FileStorage::new(
        PathBuf::from(storage_path),
        ttl_config,
    )))
}
```

**Registry pattern:**
```rust
pub struct Registry;

impl ImplementationRegistry for Registry {
    const NAME: &'static str = "file";
    type Factory = StorageFactory;
    
    fn factory() -> Self::Factory {
        create_storage
    }
}

// Dynamic registration
pub fn get_all_implementations() -> Vec<(&'static str, StorageFactory)> {
    vec![
        (file::Registry::NAME, file::Registry::factory()),
        (memory::Registry::NAME, memory::Registry::factory()),
    ]
}
```

**Benefits:**
- Configuration-driven instantiation
- Runtime backend selection
- Decoupled from concrete types
- Easy to add new implementations

**Usage:**
```toml
[storage]
type = "file"  # or "memory"
storage_path = "./data"
```

### 3. Builder Pattern

**StorageIndexes:**
```rust
let indexes = StorageIndexes::new()
    .with_field("status", "pending")
    .with_field("user_id", user_id)
    .with_field("priority", 5);
```

**Advantages:**
- Fluent API (readable, chainable)
- Optional fields without many constructors
- Type-safe construction
- Clear intent

### 4. Type-State Pattern (Implicit)

**StorageService methods enforce states:**
```rust
// Store: Can create or overwrite
pub async fn store<T: Serialize>(...) { ... }

// Update: Requires existence
pub async fn update<T: Serialize>(...) -> Result<(), StorageError> {
    if !self.backend.exists(&key).await? {
        return Err(StorageError::NotFound(key));
    }
    // ... update logic
}
```

**Benefit:** Semantic distinction prevents errors

### 5. RAII (Resource Acquisition Is Initialization)

**File locking:**
```rust
let (_lock_file,) = acquire_lock()?;
// Lock held here
operation().await?;
// Lock automatically released when _lock_file drops
```

**Benefits:**
- Automatic cleanup
- Exception-safe (even with panics)
- No explicit unlock needed
- Prevents lock leaks

### 6. Strategy Pattern

**Different backends = different strategies:**
```
StorageInterface ‚Üê Strategy abstraction
    ‚îú‚îÄ‚îÄ FileStorage (persistent strategy)
    ‚îî‚îÄ‚îÄ MemoryStorage (in-memory strategy)
```

**Context selects strategy at runtime based on configuration**

---

## Technical Deep Dive

### Concurrency Model

#### FileStorage Concurrency

**Read concurrency:**
- Multiple simultaneous reads allowed
- Uses shared locks (`lock_shared`)
- No blocking between readers
- Writers wait for readers to finish

**Write serialization:**
- Exclusive lock required (`lock_exclusive`)
- Single writer at a time per namespace
- Other writers wait
- Readers blocked during write

**Lock granularity:**
```
Global: ‚ùå (Too much contention)
Per-namespace: ‚úÖ (Optimal balance)
Per-key: ‚ùå (Too much overhead)
```

**Deadlock prevention:**
- Single lock per operation
- No nested lock acquisition
- Lock ordering not needed
- Timeouts could be added for production hardening

#### MemoryStorage Concurrency

**RwLock semantics:**
```rust
// Multiple readers
let r1 = storage.store.read().await;
let r2 = storage.store.read().await;  // ‚úÖ Allowed

// Single writer
let w = storage.store.write().await;  // ‚ùå Blocks if readers exist
```

**Tokio RwLock characteristics:**
- Async-aware (doesn't block executor)
- Fair (prevents writer starvation)
- FIFO ordering for waiting tasks

### Serialization Strategy

**Why JSON:**
- ‚úÖ Human-readable (debugging)
- ‚úÖ Language-agnostic (interoperability)
- ‚úÖ Schema flexibility (add fields without breaking)
- ‚úÖ Ubiquitous tooling support
- ‚ùå Larger than binary formats
- ‚ùå Slower than binary formats

**Alternative considerations:**
| Format | Pros | Cons | Use Case |
|--------|------|------|----------|
| JSON | Readable, flexible | Size, speed | Current choice |
| MessagePack | Compact, fast | Binary, less readable | High-throughput |
| Bincode | Very fast, small | Rust-specific | Internal only |
| Protobuf | Versioned, efficient | Complexity | Cross-service |

**Current choice rationale:**
- Solver system prioritizes debuggability
- Performance not bottleneck (I/O bound)
- Flexibility for rapid iteration

### Error Handling Philosophy

**Error types:**
```rust
pub enum StorageError {
    NotFound(String),      // Expected error (normal flow)
    Serialization(String), // Data error (fixable)
    Backend(String),       // System error (operational)
    Configuration(String), // Startup error (preventable)
    Expired(String),       // Time-based (expected)
}
```

**Handling strategy:**

1. **NotFound**: 
   - Not logged as error
   - Normal in get/exists operations
   - Caller decides if it's a problem

2. **Serialization**:
   - Indicates data corruption or version mismatch
   - Logged at WARN level
   - Query operations continue (graceful degradation)

3. **Backend**:
   - I/O errors, permissions, disk full
   - Logged at ERROR level
   - Propagated to caller for retry/fallback

4. **Configuration**:
   - Fast-fail at startup
   - Prevents invalid runtime state
   - Clear error messages

5. **Expired**:
   - Distinguished from NotFound
   - Caller may want to refresh data
   - Cleanup operations use this for metrics

### Memory Management

**FileStorage:**
- Minimal memory footprint
- Streams large files (not fully loaded)
- Index files loaded on-demand
- No caching layer (relies on OS page cache)

**MemoryStorage:**
- All data in RAM
- No eviction policy
- Unbounded growth (test scenarios only)
- Cleared on restart

**Future optimization opportunities:**
- LRU cache for frequently accessed data
- Memory-mapped files for large values
- Streaming API for large objects

### File System Layout

```
{base_path}/
‚îú‚îÄ‚îÄ namespace1_id1.bin       # Data file
‚îú‚îÄ‚îÄ namespace1_id2.bin       # Data file
‚îú‚îÄ‚îÄ namespace1.index         # Index for namespace1
‚îú‚îÄ‚îÄ namespace1.lock          # Lock file for namespace1
‚îú‚îÄ‚îÄ namespace2_id1.bin       # Different namespace
‚îú‚îÄ‚îÄ namespace2.index         # Separate index
‚îî‚îÄ‚îÄ namespace2.lock          # Separate lock
```

**Naming conventions:**
- Data: `{namespace}_{id}.bin`
- Index: `{namespace}.index`
- Lock: `{namespace}.lock`
- Temp: `{file}.tmp` (during atomic writes)

**Cleanup strategy:**
- `.tmp` files cleaned on startup
- `.lock` files removed when index is empty
- `.index` files removed when last item deleted

---

## Usage Examples

### Basic Store and Retrieve

```rust
use solver_storage::{StorageService, FileStorage, TtlConfig};
use std::path::PathBuf;

#[derive(Serialize, Deserialize)]
struct Order {
    id: String,
    user: String,
    amount: u64,
    status: String,
}

// Create storage backend
let ttl_config = TtlConfig::from_config(&config);
let backend = FileStorage::new(
    PathBuf::from("./data/storage"),
    ttl_config,
);
let service = StorageService::new(Box::new(backend));

// Store an order
let order = Order {
    id: "order123".to_string(),
    user: "alice".to_string(),
    amount: 1000,
    status: "pending".to_string(),
};

service.store("orders", &order.id, &order, None).await?;

// Retrieve the order
let retrieved: Order = service.retrieve("orders", "order123").await?;
assert_eq!(retrieved.id, "order123");
```

### Indexed Queries

```rust
use solver_storage::{StorageIndexes, QueryFilter};

// Store with indexes
let indexes = StorageIndexes::new()
    .with_field("status", "pending")
    .with_field("user", "alice")
    .with_field("amount", 1000);

service.store("orders", &order.id, &order, Some(indexes)).await?;

// Query by status
let pending_orders: Vec<(String, Order)> = service.query(
    "orders",
    QueryFilter::Equals("status".into(), json!("pending")),
).await?;

// Query multiple values
let orders_in_states: Vec<(String, Order)> = service.query(
    "orders",
    QueryFilter::In("status".into(), vec![
        json!("pending"),
        json!("processing"),
    ]),
).await?;

// Get all orders
let all_orders: Vec<(String, Order)> = service.retrieve_all("orders").await?;
```

### TTL Management

```rust
use std::time::Duration;

// Store with custom TTL
service.store_with_ttl(
    "quotes",
    &quote_id,
    &quote,
    Some(indexes),
    Some(Duration::from_secs(300)), // 5 minutes
).await?;

// Cleanup expired entries
let removed_count = service.cleanup_expired().await?;
tracing::info!("Removed {} expired items", removed_count);
```

### Update Operations

```rust
// Update existing order
let mut order: Order = service.retrieve("orders", "order123").await?;
order.status = "completed".to_string();

// Update with new indexes
let indexes = StorageIndexes::new()
    .with_field("status", "completed");

service.update("orders", "order123", &order, Some(indexes)).await?;

// Attempting to update non-existent item
match service.update("orders", "nonexistent", &order, None).await {
    Err(StorageError::NotFound(_)) => {
        // Expected - use store() to create
        service.store("orders", "neworder", &order, None).await?;
    },
    Ok(_) => {},
    Err(e) => return Err(e),
}
```

### Batch Operations

```rust
// Batch retrieval (not exposed in StorageService, but available in backend)
let keys = vec![
    "orders:order1".to_string(),
    "orders:order2".to_string(),
    "orders:order3".to_string(),
];

let results = backend.get_batch(&keys).await?;
for (key, bytes) in results {
    let order: Order = serde_json::from_slice(&bytes)?;
    println!("Order: {}", order.id);
}
```

### Configuration-Based Setup

```rust
use solver_storage::{get_all_implementations, StorageService};

// TOML configuration
let config = toml::from_str(r#"
    [storage]
    type = "file"
    storage_path = "./data/storage"
    ttl_orders = 3600
    ttl_intents = 7200
    ttl_quotes = 1800
"#)?;

// Get storage type from config
let storage_type = config.get("type")
    .and_then(|v| v.as_str())
    .unwrap_or("file");

// Find factory for type
let implementations = get_all_implementations();
let factory = implementations
    .iter()
    .find(|(name, _)| *name == storage_type)
    .map(|(_, factory)| factory)
    .ok_or("Unknown storage type")?;

// Create backend
let backend = factory(&config)?;
let service = StorageService::new(backend);
```

---

## Testing Strategy

### Unit Tests

**FileStorage tests:**
```rust
#[tokio::test]
async fn test_basic_operations() {
    let (storage, _temp_dir) = create_test_storage();
    
    // Test set and get
    storage.set_bytes("key", b"value".to_vec(), None, None).await.unwrap();
    let retrieved = storage.get_bytes("key").await.unwrap();
    assert_eq!(retrieved, b"value");
    
    // Test exists
    assert!(storage.exists("key").await.unwrap());
    
    // Test delete
    storage.delete("key").await.unwrap();
    assert!(!storage.exists("key").await.unwrap());
}
```

**Test coverage areas:**
1. ‚úÖ Basic CRUD operations
2. ‚úÖ TTL functionality and expiration
3. ‚úÖ Index creation and updates
4. ‚úÖ Index cleanup on delete
5. ‚úÖ Query filtering (all variants)
6. ‚úÖ Batch operations
7. ‚úÖ Concurrent operations
8. ‚úÖ Legacy file support
9. ‚úÖ Header serialization
10. ‚úÖ Configuration validation

### Integration Tests

**Concurrent access:**
```rust
#[tokio::test]
async fn test_concurrent_index_operations() {
    let (storage, _temp_dir) = create_test_storage();
    
    let tasks = (0..10).map(|i| {
        let storage = &storage;
        async move {
            let key = format!("orders:order{}", i);
            let indexes = StorageIndexes::new()
                .with_field("batch", "test");
            storage.set_bytes(&key, vec![], Some(indexes), None).await
        }
    });
    
    // Execute all operations concurrently
    let results: Vec<_> = futures::future::join_all(tasks).await;
    
    // All should succeed
    for result in results {
        assert!(result.is_ok());
    }
    
    // Query should find all items
    let all_items = storage.query(
        "orders",
        QueryFilter::Equals("batch".into(), json!("test")),
    ).await.unwrap();
    assert_eq!(all_items.len(), 10);
}
```

### Test Utilities

**Helper functions:**
```rust
fn create_test_storage() -> (FileStorage, TempDir) {
    let temp_dir = TempDir::new().unwrap();
    let ttl_config = TtlConfig { ttls: HashMap::new() };
    let storage = FileStorage::new(
        temp_dir.path().to_path_buf(),
        ttl_config,
    );
    (storage, temp_dir)
}

fn create_test_storage_with_ttl() -> (FileStorage, TempDir) {
    let temp_dir = TempDir::new().unwrap();
    let mut ttls = HashMap::new();
    ttls.insert(StorageKey::Orders, Duration::from_secs(1));
    let ttl_config = TtlConfig { ttls };
    let storage = FileStorage::new(
        temp_dir.path().to_path_buf(),
        ttl_config,
    );
    (storage, temp_dir)
}
```

### Mockall Integration

**Feature flag:**
```toml
[features]
testing = ["mockall"]
```

**Usage:**
```rust
#[cfg(feature = "testing")]
use solver_storage::MockStorageInterface;

#[cfg(test)]
#[tokio::test]
async fn test_with_mock() {
    let mut mock = MockStorageInterface::new();
    
    mock.expect_get_bytes()
        .with(eq("test_key"))
        .returning(|_| Ok(b"test_value".to_vec()));
    
    let result = mock.get_bytes("test_key").await.unwrap();
    assert_eq!(result, b"test_value");
}
```

---

## Performance Considerations

### Benchmarking Insights

**Operation costs (relative):**
```
Memory operations:
- get_bytes:   ~1Œºs     (HashMap lookup)
- set_bytes:   ~2Œºs     (HashMap insert)
- delete:      ~1Œºs     (HashMap remove)

File operations (SSD):
- get_bytes:   ~50Œºs    (read system call + deserialization)
- set_bytes:   ~200Œºs   (write + fsync + index update)
- delete:      ~100Œºs   (unlink + index update)
- query:       ~500Œºs   (index load + filtering)
```

### Optimization Opportunities

**1. Index caching:**
```rust
// Current: Load index on every query
let data = fs::read(&index_path).await?;
let index: NamespaceIndex = serde_json::from_slice(&data)?;

// Optimized: Cache in-memory with TTL
struct CachedIndex {
    index: NamespaceIndex,
    loaded_at: Instant,
    ttl: Duration,
}

impl FileStorage {
    fn get_cached_index(&mut self, namespace: &str) -> NamespaceIndex {
        if let Some(cached) = self.index_cache.get(namespace) {
            if cached.loaded_at.elapsed() < cached.ttl {
                return cached.index.clone();
            }
        }
        // Load and cache
        let index = self.load_index(namespace);
        self.index_cache.insert(namespace, CachedIndex { ... });
        index
    }
}
```

**2. Batch write optimization:**
```rust
// Current: Individual writes
for item in items {
    service.store(namespace, &item.id, &item, Some(indexes)).await?;
}

// Optimized: Bulk write with single index update
service.store_batch(namespace, items, indexes_fn).await?;
```

**3. Read-ahead for queries:**
```rust
// Current: Sequential reads after query
let keys = backend.query(namespace, filter).await?;
for key in keys {
    let data = backend.get_bytes(&key).await?;
    // Process data
}

// Optimized: Parallel reads with get_batch
let keys = backend.query(namespace, filter).await?;
let batch = backend.get_batch(&keys).await?;
// All data loaded in one operation
```

**4. Memory-mapped files:**
```rust
use memmap2::MmapOptions;

// For large values, use mmap instead of read
let file = File::open(path)?;
let mmap = unsafe { MmapOptions::new().map(&file)? };
let data = &mmap[FileHeader::SIZE..];
```

### Scalability Analysis

**FileStorage limits:**
- **Files per directory**: ~10,000 before performance degrades
  - Solution: Sharding by key prefix
- **Index file size**: Linear with unique values
  - Solution: Split indexes by field
- **Concurrent writers**: Lock contention at high concurrency
  - Solution: Partitioned locks or lock-free structures

**Memory usage:**
- **FileStorage**: O(1) - no in-memory data (relies on OS cache)
- **MemoryStorage**: O(n) - all data in RAM
- **Index cache**: O(m) where m = number of namespaces √ó index size

### Production Recommendations

**1. Directory structure:**
```
/data/storage/
‚îú‚îÄ‚îÄ 00/  # Shard by first 2 hex chars of hash(key)
‚îÇ   ‚îú‚îÄ‚îÄ namespace1_id1.bin
‚îÇ   ‚îî‚îÄ‚îÄ namespace1_id2.bin
‚îú‚îÄ‚îÄ 01/
‚îú‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ ff/
```

**2. Background cleanup:**
```rust
tokio::spawn(async move {
    let mut interval = tokio::time::interval(Duration::from_secs(3600));
    loop {
        interval.tick().await;
        match storage.cleanup_expired().await {
            Ok(count) => tracing::info!("Cleaned up {} expired items", count),
            Err(e) => tracing::error!("Cleanup failed: {}", e),
        }
    }
});
```

**3. Monitoring:**
```rust
// Metrics to track
- storage_operations_total{operation, status}
- storage_operation_duration_seconds{operation}
- storage_size_bytes{namespace}
- storage_items_total{namespace}
- storage_expired_items_total
- storage_query_duration_seconds{namespace}
```

**4. Configuration tuning:**
```toml
[storage]
type = "file"
storage_path = "/mnt/fast-ssd/solver-data"

# TTL per namespace (seconds)
ttl_orders = 86400       # 24 hours
ttl_intents = 172800     # 48 hours
ttl_quotes = 1800        # 30 minutes
ttl_order_by_tx_hash = 604800  # 7 days

# Performance tuning (future)
index_cache_ttl = 60     # Cache index for 60 seconds
max_batch_size = 100     # Limit batch operations
enable_compression = false  # Compress large values
```

---

## Advanced Topics

### Custom Storage Backends

To implement a new storage backend (e.g., Redis, PostgreSQL):

```rust
use async_trait::async_trait;
use solver_storage::{StorageInterface, StorageError, StorageIndexes, QueryFilter};

pub struct RedisStorage {
    client: redis::Client,
    ttl_config: TtlConfig,
}

#[async_trait]
impl StorageInterface for RedisStorage {
    async fn get_bytes(&self, key: &str) -> Result<Vec<u8>, StorageError> {
        let mut conn = self.client.get_async_connection().await
            .map_err(|e| StorageError::Backend(e.to_string()))?;
        
        let data: Option<Vec<u8>> = redis::cmd("GET")
            .arg(key)
            .query_async(&mut conn)
            .await
            .map_err(|e| StorageError::Backend(e.to_string()))?;
        
        data.ok_or_else(|| StorageError::NotFound(key.to_string()))
    }
    
    async fn set_bytes(
        &self,
        key: &str,
        value: Vec<u8>,
        indexes: Option<StorageIndexes>,
        ttl: Option<Duration>,
    ) -> Result<(), StorageError> {
        let mut conn = self.client.get_async_connection().await
            .map_err(|e| StorageError::Backend(e.to_string()))?;
        
        // Set value with TTL
        let ttl_secs = ttl.map(|d| d.as_secs()).unwrap_or(0);
        if ttl_secs > 0 {
            redis::cmd("SETEX")
                .arg(key)
                .arg(ttl_secs)
                .arg(&value)
                .query_async(&mut conn)
                .await
                .map_err(|e| StorageError::Backend(e.to_string()))?;
        } else {
            redis::cmd("SET")
                .arg(key)
                .arg(&value)
                .query_async(&mut conn)
                .await
                .map_err(|e| StorageError::Backend(e.to_string()))?;
        }
        
        // Update indexes using Redis Sets
        if let Some(indexes) = indexes {
            for (field, value) in indexes.fields {
                let index_key = format!("{}:{}:{}", 
                    key.split(':').next().unwrap_or(""),
                    field,
                    value
                );
                redis::cmd("SADD")
                    .arg(&index_key)
                    .arg(key)
                    .query_async(&mut conn)
                    .await
                    .map_err(|e| StorageError::Backend(e.to_string()))?;
            }
        }
        
        Ok(())
    }
    
    // ... other methods
}

// Registry
pub struct Registry;

impl solver_types::ImplementationRegistry for Registry {
    const NAME: &'static str = "redis";
    type Factory = solver_storage::StorageFactory;
    
    fn factory() -> Self::Factory {
        create_redis_storage
    }
}
```

### Migration Between Backends

```rust
async fn migrate_storage(
    source: &StorageService,
    dest: &StorageService,
    namespace: &str,
) -> Result<usize, StorageError> {
    let mut migrated = 0;
    
    // Get all items from source
    let items: Vec<(String, serde_json::Value)> = source
        .retrieve_all(namespace)
        .await?;
    
    // Copy to destination
    for (id, data) in items {
        dest.store(namespace, &id, &data, None).await?;
        migrated += 1;
    }
    
    Ok(migrated)
}
```

---

## Conclusion

The `solver-storage` crate provides a robust, flexible storage abstraction for the OIF solver system. Key strengths:

‚úÖ **Pluggable architecture** - Easy to add new backends  
‚úÖ **Type safety** - Compile-time guarantees for data operations  
‚úÖ **Production-ready FileStorage** - TTL, indexing, atomic writes, file locking  
‚úÖ **Testing-friendly MemoryStorage** - Simple, fast, no setup required  
‚úÖ **Query capabilities** - Field-based filtering for efficient data retrieval  
‚úÖ **Concurrency support** - Thread-safe with proper locking semantics  
‚úÖ **Configuration-driven** - Factory pattern with runtime backend selection  

### Future Enhancements

**Short-term:**
- Index caching for faster queries
- Compression support for large values
- Directory sharding for scalability
- Streaming API for large objects

**Long-term:**
- Distributed storage backends (Redis, DynamoDB)
- Replication and consistency guarantees
- Cross-region storage with CRDTs
- Storage analytics and optimization tools

---

## Appendix

### File Format Version History

| Version | Changes | Compatibility |
|---------|---------|---------------|
| 1 (current) | Initial format with TTL support | Reads legacy files without headers |

### Configuration Reference

```toml
[storage]
# Backend type: "file" or "memory"
type = "file"

# FileStorage-specific options
storage_path = "./data/storage"

# TTL configuration (seconds, 0 = permanent)
ttl_orders = 86400              # 24 hours
ttl_intents = 172800            # 48 hours  
ttl_quotes = 1800               # 30 minutes
ttl_order_by_tx_hash = 604800   # 7 days
```

### Error Reference

| Error | Cause | Resolution |
|-------|-------|------------|
| `NotFound` | Key doesn't exist | Normal - check before operations |
| `Serialization` | Invalid JSON or type mismatch | Verify data structure compatibility |
| `Backend` | I/O error, permissions, disk full | Check system resources, permissions |
| `Configuration` | Invalid config value | Validate config against schema |
| `Expired` | Data past TTL | Normal - refresh or accept staleness |

### Dependencies Graph

```
solver-storage
‚îú‚îÄ‚îÄ async-trait (trait async support)
‚îú‚îÄ‚îÄ fs2 (file locking)
‚îú‚îÄ‚îÄ serde (serialization framework)
‚îú‚îÄ‚îÄ serde_json (JSON format)
‚îú‚îÄ‚îÄ solver-types (common types)
‚îÇ   ‚îî‚îÄ‚îÄ Defines: StorageKey, ConfigSchema, ValidationError
‚îú‚îÄ‚îÄ thiserror (error derive)
‚îú‚îÄ‚îÄ tokio (async runtime)
‚îÇ   ‚îú‚îÄ‚îÄ fs (async file operations)
‚îÇ   ‚îú‚îÄ‚îÄ sync (RwLock, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ task (spawn_blocking)
‚îú‚îÄ‚îÄ toml (config parsing)
‚îî‚îÄ‚îÄ tracing (logging)
```

---

**Document Version:** 1.0  
**Last Updated:** 2025-10-09  
**Author:** Technical Analysis System  
**Status:** Complete ‚úì

